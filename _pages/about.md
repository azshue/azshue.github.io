---
permalink: /
title: ""
excerpt:
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About me     
   I am a researcher at Salesforce Research, I work on large multimodal models. Before joining Salesforce, I obtained my Ph.D. degree in Computer Science from the University of Maryland, College Park (UMD) in 2024, advised by [Tom Goldstein](https://www.cs.umd.edu/~tomg/). I mainly worked on research topics relevant to AI/ML safety and trustworthiness during my Ph.D. years.     

   During my years at UMD, I have interned at Nvidia, Salesforce, and Google as a research intern, where I have collaborated with many awesome professors and researchers. Before that, I obtained my bachelor's degree in information security at the University of Science and Technology of China (USTC) in June 2019.      
  


## News
* **[08/2024]** Technical report out: [xGen-MM (BLIP-3): A Family of Open Large Multimodal](https://arxiv.org/pdf/2408.08872), along with xGen-MM-v1.5 model release. Been driving the instruction tuning efforts in model development. [\[<u>arXiv</u>\]](https://arxiv.org/pdf/2408.08872) [\[<u>X Live with @AK</u>\]](https://x.com/_akhaliq/status/1825738604435419497), [\[<u>ü§ó Model card</u>\]](https://huggingface.co/Salesforce/xgen-mm-phi3-mini-instruct-interleave-r-v1.5)
* **[05/2024]** Released Salesforce's multimodal large language models - xGen-MM, the enhanced continuation of our BLIP series. [\[<u>Twitter</u>\]](https://x.com/ManliShu/status/1789151298258108580), [\[<u>ü§ó Model card</u>\]](https://huggingface.co/Salesforce/xgen-mm-phi3-mini-instruct-r-v1)
* **[05/2024]** Gave an oral presentation at ICRA'24 on a previous internship project about 3D object detection. [\[<u>paper</u>\]](https://arxiv.org/pdf/2301.02650) [\[<u>slides</u>\]](https://azshue.github.io/files/icra-2024-presentation-pdf.pdf)
* **[02/2024]** Two preprints out (done at UMD). One studied data poisoning on vision-language models, another explored adversarial attacks on LLMs.
* **[01/2024]** Joined Salesforce Research. Relocated to Palo Alto, CA. 
* **[11/2023]** Defended my Ph.D. dissertation üíê üë©üèª‚Äçüéì
* **[09/2023]** One paper accepted at NeurIPS. We studied a novel vulnerability of aligned language models from the perspective of data security. [\[<u>paper</u>\]](https://proceedings.neurips.cc/paper_files/paper/2023/file/c2a8060fd22744b38177d9e428a052e0-Paper-Conference.pdf)[\[<u>code</u>\]](https://github.com/azshue/AutoPoison)
* **[11/2022]** In New Orleans attending NeurIPS. Presented the work done at Nvidia about prompt tuning for vision-language models. (Excited to attend my first in-person academic conference. I wish I had printed a bigger poster.)[\[<u>paper</u>\]](https://arxiv.org/pdf/2209.07511)[<u>project page</u>\]](https://azshue.github.io/TPT/)[\[<u>code</u>\]](https://github.com/azshue/TPT)


## Selected Publications

  *For the complete list of publications, please refer to my [google scholar](https://scholar.google.com/citations?user=WPYkxjgAAAAJ&hl=en) page*

  * **On the Exploitability of Instruction Tuning**    
    **M. Shu**, J. Wang, C. Zhu, J. Geiping, C. Xiao, T. Goldstein    
    *to appear at NeurIPS 2023*  
    [[Preprint](https://arxiv.org/pdf/2306.17194.pdf)] [[Code](https://github.com/azshue/AutoPoison)]


  * **On the Reliability of Watermarks for Large Language Models**    
    J. Kirchenbauer\*, J. Geiping\*, Y. Wen, **M. Shu**, K. Saifullah, K. Kong, K. Fernando, A. Saha, M. Goldblum, T. Goldstein    
    *Under review*    
    [[Preprint](https://arxiv.org/pdf/2306.04634.pdf)] [[Code](https://github.com/jwkirchenbauer/lm-watermarking)]


  * **Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models**    
    **M. Shu**, W. Nie, D.A. Huang, Z. Yu, T. Goldstein, A. Anandkumar, C. Xiao    
    *NeurIPS 2022*     
    [[Paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/5bf2b802e24106064dc547ae9283bb0c-Paper-Conference.pdf)] [[Code](https://github.com/azshue/TPT)] [[Project page](https://azshue.github.io/TPT)]

  * **Where do Models go Wrong? Parameter-Space Saliency Maps for Explainability**    
    R. Levin\*, **M. Shu\***, E. Borgnia\*, F. Huang, M. Goldblum, T. Goldstein    
    *NeurIPS 2022*     
    [[Paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/6450ea28ebbc8437bc38775157818172-Paper-Conference.pdf)] [[Code](https://github.com/azshue/parameter-space-saliency)]

  * **The Close Relationship Between Contrastive Learning and Meta-Learning**    
    R. Ni\*, **M. Shu\***, H. Souri, M. Goldblum, T. Goldstein    
    *ICLR 2022*    
    [[Paper](https://openreview.net/pdf?id=gICys3ITSmj)] [[Code](https://github.com/RenkunNi/MetaContrastive)]

  
  * **Encoding Robustness to Image Style via Adversarial Feature Perturbation**    
    **M. Shu**, Z. Wu, M. Goldblum, T. Goldstein    
    *NeurIPS 2021*     
    [[Paper](https://proceedings.neurips.cc/paper/2021/file/ec20019911a77ad39d023710be68aaa1-Paper.pdf)] [[Code](https://github.com/azshue/AdvBN)]

  * **Adversarial Differentiable Data Augmentation for Autonomous Systems**    
    **M. Shu**, Y. Shen, M.C. Lin, T. Goldstein    
    *ICRA 2021*     
    [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9561205)] [[Code](https://github.com/azshue/adversarial_data_augmentation)]
  
  * **Model-Agnostic Hierarchical Attention for 3D Object Detection**    
    **M. Shu**, L. Xue, R. Mart\'in-Mart\'in, C. Xiong, T. Goldstein, J.C. Niebles, R. Xu.    
    *Under review*     
    [[Preprint](https://arxiv.org/pdf/2301.02650.pdf)]


## Services

Conference reviewer:  NeurIPS, ICML, ICLR, CVPR, ICCV, IROS   
Journal reviewer: IJCV    

## More about me (misc)

Things I like: Sun, seaside, going for a walk, yoga, weightlifting, civ 6, the legend of Zelda - BotW...
